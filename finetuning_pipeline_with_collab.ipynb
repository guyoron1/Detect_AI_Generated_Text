{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Setting up ipynb env for running code from GitHub."
      ],
      "metadata": {
        "id": "HW8s57WFZ6ct"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nH5BzzRMZnfW",
        "outputId": "f2fc1974-ec7d-4785-fc49-2c1697b33905"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'Detect_AI_Generated_Text'...\n",
            "remote: Enumerating objects: 271, done.\u001b[K\n",
            "remote: Counting objects: 100% (139/139), done.\u001b[K\n",
            "remote: Compressing objects: 100% (106/106), done.\u001b[K\n",
            "remote: Total 271 (delta 80), reused 79 (delta 33), pack-reused 132 (from 1)\u001b[K\n",
            "Receiving objects: 100% (271/271), 91.48 MiB | 25.54 MiB/s, done.\n",
            "Resolving deltas: 100% (139/139), done.\n"
          ]
        }
      ],
      "source": [
        "# For initial cloning. Do not rerun.\n",
        "\n",
        "!git clone https://github.com/guyoron1/Detect_AI_Generated_Text.git\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Make sure we are working from GH root.\n",
        "%cd /content/Detect_AI_Generated_Text\n",
        "%mkdir ./data\n",
        "%mkdir ./models\n"
      ],
      "metadata": {
        "id": "PcPy-Q_XaHKE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "912145fd-4c65-4e1d-cd5d-3c4103a89fc3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/Detect_AI_Generated_Text\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## Mount Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Copy the zip file to the local working directory\n",
        "!cp /content/drive/MyDrive/external_sources.zip .\n",
        "\n",
        "# Unzip it into the target directory (e.g., /content/Detect_AI_Generated_Text)\n",
        "!unzip -q external_sources.zip -d /content/Detect_AI_Generated_Text/"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "77CAItpaof1N",
        "outputId": "c5bae214-7dac-4a85-c756-76e080bfcba6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "replace /content/Detect_AI_Generated_Text/external_sources/llm-detect-ai-generated-text/train_prompts.csv? [y]es, [n]o, [A]ll, [N]one, [r]ename: שׁ\n",
            "error:  invalid response [שׁ]\n",
            "replace /content/Detect_AI_Generated_Text/external_sources/llm-detect-ai-generated-text/train_prompts.csv? [y]es, [n]o, [A]ll, [N]one, [r]ename: A\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Install requirements..\n",
        "!pip uninstall -y tokenizers\n",
        "!pip install transformers datasets tokenizers openai matplotlib scikit-learn matplotlib loguru"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BqkzTt7AvkpE",
        "outputId": "2f1015e0-f278-4b71-c12f-1303d5400506"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found existing installation: tokenizers 0.21.1\n",
            "Uninstalling tokenizers-0.21.1:\n",
            "  Successfully uninstalled tokenizers-0.21.1\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (4.51.3)\n",
            "Collecting datasets\n",
            "  Downloading datasets-3.5.1-py3-none-any.whl.metadata (19 kB)\n",
            "Collecting tokenizers\n",
            "  Downloading tokenizers-0.21.1-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.8 kB)\n",
            "Requirement already satisfied: openai in /usr/local/lib/python3.11/dist-packages (1.76.0)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (3.10.0)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (1.6.1)\n",
            "Collecting loguru\n",
            "  Downloading loguru-0.7.3-py3-none-any.whl.metadata (22 kB)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from transformers) (3.18.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.30.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.30.2)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2.0.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2024.11.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from transformers) (2.32.3)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.5.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.11/dist-packages (from transformers) (4.67.1)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (18.1.0)\n",
            "Collecting dill<0.3.9,>=0.3.0 (from datasets)\n",
            "  Downloading dill-0.3.8-py3-none-any.whl.metadata (10 kB)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from datasets) (2.2.2)\n",
            "Collecting xxhash (from datasets)\n",
            "  Downloading xxhash-3.5.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n",
            "Collecting multiprocess<0.70.17 (from datasets)\n",
            "  Downloading multiprocess-0.70.16-py311-none-any.whl.metadata (7.2 kB)\n",
            "Collecting fsspec<=2025.3.0,>=2023.1.0 (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets)\n",
            "  Downloading fsspec-2025.3.0-py3-none-any.whl.metadata (11 kB)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.11/dist-packages (from datasets) (3.11.15)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from openai) (4.9.0)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.11/dist-packages (from openai) (1.9.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from openai) (0.28.1)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from openai) (0.9.0)\n",
            "Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.11/dist-packages (from openai) (2.11.3)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.11/dist-packages (from openai) (1.3.1)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.11 in /usr/local/lib/python3.11/dist-packages (from openai) (4.13.2)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (1.3.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (4.57.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (1.4.8)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (11.2.1)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (3.2.3)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (2.9.0.post0)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.15.2)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (3.6.0)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.11/dist-packages (from anyio<5,>=3.5.0->openai) (3.10)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.6.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (6.4.3)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (0.3.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.20.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->openai) (2025.4.26)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->openai) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.16.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1.9.0->openai) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.1 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1.9.0->openai) (2.33.1)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1.9.0->openai) (0.4.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.7->matplotlib) (1.17.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.4.1)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2.4.0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2025.2)\n",
            "Downloading datasets-3.5.1-py3-none-any.whl (491 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m491.4/491.4 kB\u001b[0m \u001b[31m35.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tokenizers-0.21.1-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.0/3.0 MB\u001b[0m \u001b[31m102.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading loguru-0.7.3-py3-none-any.whl (61 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.6/61.6 kB\u001b[0m \u001b[31m7.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading dill-0.3.8-py3-none-any.whl (116 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.3/116.3 kB\u001b[0m \u001b[31m14.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading fsspec-2025.3.0-py3-none-any.whl (193 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m193.6/193.6 kB\u001b[0m \u001b[31m23.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading multiprocess-0.70.16-py311-none-any.whl (143 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m143.5/143.5 kB\u001b[0m \u001b[31m16.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading xxhash-3.5.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (194 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.8/194.8 kB\u001b[0m \u001b[31m22.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: xxhash, loguru, fsspec, dill, multiprocess, tokenizers, datasets\n",
            "  Attempting uninstall: fsspec\n",
            "    Found existing installation: fsspec 2025.3.2\n",
            "    Uninstalling fsspec-2025.3.2:\n",
            "      Successfully uninstalled fsspec-2025.3.2\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "torch 2.6.0+cu124 requires nvidia-cublas-cu12==12.4.5.8; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cublas-cu12 12.5.3.2 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-cuda-cupti-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cuda-cupti-cu12 12.5.82 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-cuda-nvrtc-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cuda-nvrtc-cu12 12.5.82 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-cuda-runtime-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cuda-runtime-cu12 12.5.82 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-cudnn-cu12==9.1.0.70; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cudnn-cu12 9.3.0.75 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-cufft-cu12==11.2.1.3; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cufft-cu12 11.2.3.61 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-curand-cu12==10.3.5.147; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-curand-cu12 10.3.6.82 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-cusolver-cu12==11.6.1.9; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cusolver-cu12 11.6.3.83 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-cusparse-cu12==12.3.1.170; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cusparse-cu12 12.5.1.3 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-nvjitlink-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-nvjitlink-cu12 12.5.82 which is incompatible.\n",
            "gcsfs 2025.3.2 requires fsspec==2025.3.2, but you have fsspec 2025.3.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed datasets-3.5.1 dill-0.3.8 fsspec-2025.3.0 loguru-0.7.3 multiprocess-0.70.16 tokenizers-0.21.1 xxhash-3.5.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git pull"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6mlysvnS0qQr",
        "outputId": "01efc839-581d-4427-ca82-d8e52ca21410"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "remote: Enumerating objects: 5, done.\u001b[K\n",
            "remote: Counting objects:  20% (1/5)\u001b[K\rremote: Counting objects:  40% (2/5)\u001b[K\rremote: Counting objects:  60% (3/5)\u001b[K\rremote: Counting objects:  80% (4/5)\u001b[K\rremote: Counting objects: 100% (5/5)\u001b[K\rremote: Counting objects: 100% (5/5), done.\u001b[K\n",
            "remote: Compressing objects: 100% (1/1)\u001b[K\rremote: Compressing objects: 100% (1/1), done.\u001b[K\n",
            "remote: Total 3 (delta 2), reused 3 (delta 2), pack-reused 0 (from 0)\u001b[K\n",
            "Unpacking objects:  33% (1/3)\rUnpacking objects:  66% (2/3)\rUnpacking objects: 100% (3/3)\rUnpacking objects: 100% (3/3), 282 bytes | 282.00 KiB/s, done.\n",
            "From https://github.com/guyoron1/Detect_AI_Generated_Text\n",
            "   243fe4a..dfc211c  main       -> origin/main\n",
            "Updating 243fe4a..dfc211c\n",
            "Fast-forward\n",
            " finetuning.py | 2 \u001b[32m+\u001b[m\u001b[31m-\u001b[m\n",
            " 1 file changed, 1 insertion(+), 1 deletion(-)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# All we need is to run finetuning.py from the command line.\n",
        "!python finetuning.py \\\n",
        "  --sources outfox fpe daigt persuade \\\n",
        "  --save_dataset \\\n",
        "  --sample_size 100000\n"
      ],
      "metadata": {
        "id": "OGfvSzD-aaxN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1f0c6593-db06-4853-b074-609d1e643ad6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2025-05-01 21:09:51.454250: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1746133791.473878    3945 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1746133791.479970    3945 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2025-05-01 21:09:51.500441: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "config.json: 100% 662/662 [00:00<00:00, 4.98MB/s]\n",
            "Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n",
            "model.safetensors: 100% 3.13G/3.13G [00:13<00:00, 235MB/s]\n",
            "generation_config.json: 100% 147/147 [00:00<00:00, 756kB/s]\n",
            "tokenizer_config.json: 100% 2.54k/2.54k [00:00<00:00, 15.8MB/s]\n",
            "Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n",
            "spiece.model: 100% 792k/792k [00:00<00:00, 117MB/s]\n",
            "tokenizer.json: 100% 2.42M/2.42M [00:00<00:00, 3.70MB/s]\n",
            "special_tokens_map.json: 100% 2.20k/2.20k [00:00<00:00, 15.1MB/s]\n",
            "Device set to use cuda:0\n",
            "/content/Detect_AI_Generated_Text/fetch_data.py:110: DtypeWarning: Columns (17) have mixed types. Specify dtype option on import or set low_memory=False.\n",
            "  df = pd.read_csv(datapath)\n",
            "/content/Detect_AI_Generated_Text/format.py:82: DtypeWarning: Columns (17) have mixed types. Specify dtype option on import or set low_memory=False.\n",
            "  df = pd.read_csv(path)\n",
            "\n",
            "\u001b[32m2025-05-01 21:10:34.015\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m296\u001b[0m - \u001b[34m\u001b[1mGenerated column - Ones: 50000, Zeros: 50000\u001b[0m\n",
            "\u001b[32m2025-05-01 21:10:43.482\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m305\u001b[0m - \u001b[34m\u001b[1mLoaded and saved datasets successfuly. Performing finetuning.\u001b[0m\n",
            "\u001b[32m2025-05-01 21:10:43.483\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfinetune\u001b[0m:\u001b[36m126\u001b[0m - \u001b[34m\u001b[1mLoading tokenizer and model.\u001b[0m\n",
            "tokenizer_config.json: 100% 48.0/48.0 [00:00<00:00, 290kB/s]\n",
            "config.json: 100% 483/483 [00:00<00:00, 3.17MB/s]\n",
            "vocab.txt: 100% 232k/232k [00:00<00:00, 1.02MB/s]\n",
            "tokenizer.json: 100% 466k/466k [00:00<00:00, 17.8MB/s]\n",
            "Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n",
            "model.safetensors: 100% 268M/268M [00:00<00:00, 345MB/s]\n",
            "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "\u001b[32m2025-05-01 21:10:48.587\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfinetune\u001b[0m:\u001b[36m131\u001b[0m - \u001b[34m\u001b[1mModel moved to CUDA.\u001b[0m\n",
            "Map: 100% 80000/80000 [02:20<00:00, 568.50 examples/s]\n",
            "Map: 100% 20000/20000 [00:35<00:00, 555.84 examples/s]\n",
            "\u001b[32m2025-05-01 21:13:47.272\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfinetune\u001b[0m:\u001b[36m145\u001b[0m - \u001b[34m\u001b[1mDataset tokenized successfully.\u001b[0m\n",
            "/content/Detect_AI_Generated_Text/finetuning.py:164: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
            "  trainer = Trainer(\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m The `run_name` is currently set to the same value as `TrainingArguments.output_dir`. If this was not intended, please specify a different run name by setting the `TrainingArguments.run_name` parameter.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: (1) Create a W&B account\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: (2) Use an existing W&B account\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: (3) Don't visualize my results\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Enter your choice: 3\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: You chose \"Don't visualize my results\"\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.19.10\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: W&B syncing is set to \u001b[1m`offline`\u001b[0m in this directory. Run \u001b[1m`wandb online`\u001b[0m or set \u001b[1mWANDB_MODE=online\u001b[0m to enable cloud syncing.\n",
            "{'loss': 0.6855, 'grad_norm': 1.5981875658035278, 'learning_rate': 3.6e-07, 'epoch': 0.0}\n",
            "{'loss': 0.6907, 'grad_norm': 1.72158944606781, 'learning_rate': 7.6e-07, 'epoch': 0.0}\n",
            "{'loss': 0.6957, 'grad_norm': 1.2341835498809814, 'learning_rate': 1.1600000000000001e-06, 'epoch': 0.01}\n",
            "{'loss': 0.7019, 'grad_norm': 1.2365221977233887, 'learning_rate': 1.56e-06, 'epoch': 0.01}\n",
            "{'loss': 0.6939, 'grad_norm': 1.076704502105713, 'learning_rate': 1.9600000000000003e-06, 'epoch': 0.01}\n",
            "{'loss': 0.689, 'grad_norm': 1.856320858001709, 'learning_rate': 2.3600000000000003e-06, 'epoch': 0.01}\n",
            "{'loss': 0.6925, 'grad_norm': 1.281984806060791, 'learning_rate': 2.7600000000000003e-06, 'epoch': 0.01}\n",
            "{'loss': 0.6731, 'grad_norm': 1.2486780881881714, 'learning_rate': 3.1600000000000002e-06, 'epoch': 0.02}\n",
            "{'loss': 0.6648, 'grad_norm': 1.5070769786834717, 'learning_rate': 3.5600000000000002e-06, 'epoch': 0.02}\n",
            "{'loss': 0.6399, 'grad_norm': 1.3593075275421143, 'learning_rate': 3.96e-06, 'epoch': 0.02}\n",
            "{'loss': 0.5913, 'grad_norm': 2.47149920463562, 'learning_rate': 4.360000000000001e-06, 'epoch': 0.02}\n",
            "{'loss': 0.5466, 'grad_norm': 2.1410486698150635, 'learning_rate': 4.76e-06, 'epoch': 0.02}\n",
            "{'loss': 0.4921, 'grad_norm': 2.607314348220825, 'learning_rate': 5.1600000000000006e-06, 'epoch': 0.03}\n",
            "{'loss': 0.4289, 'grad_norm': 2.1306607723236084, 'learning_rate': 5.560000000000001e-06, 'epoch': 0.03}\n",
            "{'loss': 0.3494, 'grad_norm': 2.186319351196289, 'learning_rate': 5.9600000000000005e-06, 'epoch': 0.03}\n",
            "{'loss': 0.3155, 'grad_norm': 1.7061034440994263, 'learning_rate': 6.360000000000001e-06, 'epoch': 0.03}\n",
            "{'loss': 0.3093, 'grad_norm': 1.502162218093872, 'learning_rate': 6.760000000000001e-06, 'epoch': 0.03}\n",
            "{'loss': 0.2735, 'grad_norm': 2.4121527671813965, 'learning_rate': 7.16e-06, 'epoch': 0.04}\n",
            "{'loss': 0.2799, 'grad_norm': 2.4874207973480225, 'learning_rate': 7.5600000000000005e-06, 'epoch': 0.04}\n",
            "{'loss': 0.301, 'grad_norm': 5.50423526763916, 'learning_rate': 7.960000000000002e-06, 'epoch': 0.04}\n",
            "{'loss': 0.2892, 'grad_norm': 0.8830947279930115, 'learning_rate': 8.36e-06, 'epoch': 0.04}\n",
            "{'loss': 0.2839, 'grad_norm': 3.1235852241516113, 'learning_rate': 8.76e-06, 'epoch': 0.04}\n",
            "{'loss': 0.2011, 'grad_norm': 1.7219487428665161, 'learning_rate': 9.16e-06, 'epoch': 0.05}\n",
            "{'loss': 0.3549, 'grad_norm': 6.370559215545654, 'learning_rate': 9.56e-06, 'epoch': 0.05}\n",
            "{'loss': 0.3183, 'grad_norm': 2.4388351440429688, 'learning_rate': 9.960000000000001e-06, 'epoch': 0.05}\n",
            "{'loss': 0.3631, 'grad_norm': 6.1545233726501465, 'learning_rate': 1.036e-05, 'epoch': 0.05}\n",
            "{'loss': 0.3008, 'grad_norm': 2.2505173683166504, 'learning_rate': 1.0760000000000002e-05, 'epoch': 0.05}\n",
            "{'loss': 0.2664, 'grad_norm': 4.258127212524414, 'learning_rate': 1.1160000000000002e-05, 'epoch': 0.06}\n",
            "{'loss': 0.2763, 'grad_norm': 4.147476673126221, 'learning_rate': 1.156e-05, 'epoch': 0.06}\n",
            "{'loss': 0.236, 'grad_norm': 2.113551139831543, 'learning_rate': 1.196e-05, 'epoch': 0.06}\n",
            "{'loss': 0.23, 'grad_norm': 1.3885992765426636, 'learning_rate': 1.236e-05, 'epoch': 0.06}\n",
            "{'loss': 0.2207, 'grad_norm': 1.4792150259017944, 'learning_rate': 1.2760000000000001e-05, 'epoch': 0.06}\n",
            "{'loss': 0.1882, 'grad_norm': 2.3452746868133545, 'learning_rate': 1.3160000000000001e-05, 'epoch': 0.07}\n",
            "{'loss': 0.3384, 'grad_norm': 4.430643081665039, 'learning_rate': 1.3560000000000002e-05, 'epoch': 0.07}\n",
            "{'loss': 0.2762, 'grad_norm': 2.7971789836883545, 'learning_rate': 1.396e-05, 'epoch': 0.07}\n",
            "{'loss': 0.2986, 'grad_norm': 10.691878318786621, 'learning_rate': 1.4360000000000001e-05, 'epoch': 0.07}\n",
            "{'loss': 0.4336, 'grad_norm': 10.621253967285156, 'learning_rate': 1.4760000000000001e-05, 'epoch': 0.07}\n",
            "{'loss': 0.3179, 'grad_norm': 2.615339756011963, 'learning_rate': 1.516e-05, 'epoch': 0.08}\n",
            "{'loss': 0.2868, 'grad_norm': 3.430947780609131, 'learning_rate': 1.556e-05, 'epoch': 0.08}\n",
            "{'loss': 0.357, 'grad_norm': 2.6758310794830322, 'learning_rate': 1.5960000000000003e-05, 'epoch': 0.08}\n",
            "{'loss': 0.2141, 'grad_norm': 2.951314926147461, 'learning_rate': 1.636e-05, 'epoch': 0.08}\n",
            "{'loss': 0.2618, 'grad_norm': 3.310701370239258, 'learning_rate': 1.6760000000000002e-05, 'epoch': 0.08}\n",
            "{'loss': 0.178, 'grad_norm': 0.8814874887466431, 'learning_rate': 1.7160000000000002e-05, 'epoch': 0.09}\n",
            "{'loss': 0.3192, 'grad_norm': 5.23383903503418, 'learning_rate': 1.756e-05, 'epoch': 0.09}\n",
            "{'loss': 0.3657, 'grad_norm': 2.418262243270874, 'learning_rate': 1.796e-05, 'epoch': 0.09}\n",
            "{'loss': 0.2315, 'grad_norm': 2.2005412578582764, 'learning_rate': 1.8360000000000004e-05, 'epoch': 0.09}\n",
            "{'loss': 0.3684, 'grad_norm': 2.7844178676605225, 'learning_rate': 1.876e-05, 'epoch': 0.09}\n",
            "{'loss': 0.2093, 'grad_norm': 2.5569815635681152, 'learning_rate': 1.916e-05, 'epoch': 0.1}\n",
            "{'loss': 0.2442, 'grad_norm': 9.972506523132324, 'learning_rate': 1.9560000000000002e-05, 'epoch': 0.1}\n",
            "{'loss': 0.2339, 'grad_norm': 6.676756381988525, 'learning_rate': 1.9960000000000002e-05, 'epoch': 0.1}\n",
            "{'loss': 0.206, 'grad_norm': 2.2919318675994873, 'learning_rate': 1.999076923076923e-05, 'epoch': 0.1}\n",
            "{'loss': 0.1944, 'grad_norm': 2.789515733718872, 'learning_rate': 1.9980512820512822e-05, 'epoch': 0.1}\n",
            "{'loss': 0.2451, 'grad_norm': 8.063765525817871, 'learning_rate': 1.9970256410256414e-05, 'epoch': 0.11}\n",
            "{'loss': 0.2363, 'grad_norm': 1.8157614469528198, 'learning_rate': 1.9960000000000002e-05, 'epoch': 0.11}\n",
            "{'loss': 0.3113, 'grad_norm': 4.6371283531188965, 'learning_rate': 1.994974358974359e-05, 'epoch': 0.11}\n",
            "{'loss': 0.2122, 'grad_norm': 4.308547019958496, 'learning_rate': 1.993948717948718e-05, 'epoch': 0.11}\n",
            "{'loss': 0.2055, 'grad_norm': 1.2586690187454224, 'learning_rate': 1.9929230769230773e-05, 'epoch': 0.11}\n",
            "{'loss': 0.1718, 'grad_norm': 3.5915093421936035, 'learning_rate': 1.991897435897436e-05, 'epoch': 0.12}\n",
            "{'loss': 0.2133, 'grad_norm': 1.8046876192092896, 'learning_rate': 1.990871794871795e-05, 'epoch': 0.12}\n",
            "{'loss': 0.3728, 'grad_norm': 4.517943859100342, 'learning_rate': 1.989846153846154e-05, 'epoch': 0.12}\n",
            "{'loss': 0.2925, 'grad_norm': 2.182558059692383, 'learning_rate': 1.988820512820513e-05, 'epoch': 0.12}\n",
            "{'loss': 0.2585, 'grad_norm': 3.868872880935669, 'learning_rate': 1.9877948717948717e-05, 'epoch': 0.12}\n",
            "{'loss': 0.2615, 'grad_norm': 2.937610387802124, 'learning_rate': 1.986769230769231e-05, 'epoch': 0.13}\n",
            "{'loss': 0.2152, 'grad_norm': 1.1184827089309692, 'learning_rate': 1.98574358974359e-05, 'epoch': 0.13}\n",
            "{'loss': 0.2647, 'grad_norm': 5.878085613250732, 'learning_rate': 1.9847179487179488e-05, 'epoch': 0.13}\n",
            "{'loss': 0.2547, 'grad_norm': 7.8624186515808105, 'learning_rate': 1.983692307692308e-05, 'epoch': 0.13}\n",
            "{'loss': 0.2425, 'grad_norm': 5.979410648345947, 'learning_rate': 1.9826666666666668e-05, 'epoch': 0.13}\n",
            "{'loss': 0.2246, 'grad_norm': 1.3266018629074097, 'learning_rate': 1.981641025641026e-05, 'epoch': 0.14}\n",
            "{'loss': 0.1863, 'grad_norm': 7.029272556304932, 'learning_rate': 1.9806153846153847e-05, 'epoch': 0.14}\n",
            "{'loss': 0.3249, 'grad_norm': 4.316527843475342, 'learning_rate': 1.979589743589744e-05, 'epoch': 0.14}\n",
            "{'loss': 0.1584, 'grad_norm': 2.594491958618164, 'learning_rate': 1.9785641025641027e-05, 'epoch': 0.14}\n",
            "{'loss': 0.2962, 'grad_norm': 4.797909736633301, 'learning_rate': 1.9775384615384615e-05, 'epoch': 0.14}\n",
            "{'loss': 0.234, 'grad_norm': 3.001274347305298, 'learning_rate': 1.9765128205128206e-05, 'epoch': 0.15}\n",
            "{'loss': 0.1697, 'grad_norm': 1.8368960618972778, 'learning_rate': 1.9754871794871798e-05, 'epoch': 0.15}\n",
            "{'loss': 0.2166, 'grad_norm': 1.7623111009597778, 'learning_rate': 1.9744615384615386e-05, 'epoch': 0.15}\n",
            "{'loss': 0.1564, 'grad_norm': 1.622815489768982, 'learning_rate': 1.9734358974358974e-05, 'epoch': 0.15}\n",
            "{'loss': 0.2003, 'grad_norm': 2.2994277477264404, 'learning_rate': 1.9724102564102566e-05, 'epoch': 0.15}\n",
            "{'loss': 0.1984, 'grad_norm': 6.920971393585205, 'learning_rate': 1.9713846153846154e-05, 'epoch': 0.16}\n",
            "{'loss': 0.3405, 'grad_norm': 1.6881260871887207, 'learning_rate': 1.9703589743589745e-05, 'epoch': 0.16}\n",
            "{'loss': 0.1471, 'grad_norm': 1.5229301452636719, 'learning_rate': 1.9693333333333337e-05, 'epoch': 0.16}\n",
            "{'loss': 0.2465, 'grad_norm': 7.557176113128662, 'learning_rate': 1.9683076923076925e-05, 'epoch': 0.16}\n",
            "{'loss': 0.1363, 'grad_norm': 1.3308979272842407, 'learning_rate': 1.9672820512820513e-05, 'epoch': 0.16}\n",
            "{'loss': 0.1536, 'grad_norm': 4.492098331451416, 'learning_rate': 1.9662564102564104e-05, 'epoch': 0.17}\n",
            "{'loss': 0.2085, 'grad_norm': 2.726691484451294, 'learning_rate': 1.9652307692307696e-05, 'epoch': 0.17}\n",
            "{'loss': 0.2044, 'grad_norm': 1.3353883028030396, 'learning_rate': 1.9642051282051284e-05, 'epoch': 0.17}\n",
            "{'loss': 0.2336, 'grad_norm': 1.8282856941223145, 'learning_rate': 1.9631794871794872e-05, 'epoch': 0.17}\n",
            "{'loss': 0.1742, 'grad_norm': 2.2201316356658936, 'learning_rate': 1.9621538461538464e-05, 'epoch': 0.17}\n",
            "{'loss': 0.2237, 'grad_norm': 3.086104154586792, 'learning_rate': 1.9611282051282052e-05, 'epoch': 0.18}\n",
            "{'loss': 0.2604, 'grad_norm': 1.5557559728622437, 'learning_rate': 1.9601025641025643e-05, 'epoch': 0.18}\n",
            "{'loss': 0.2411, 'grad_norm': 2.8844683170318604, 'learning_rate': 1.9590769230769235e-05, 'epoch': 0.18}\n",
            "{'loss': 0.2031, 'grad_norm': 1.605351209640503, 'learning_rate': 1.9580512820512823e-05, 'epoch': 0.18}\n",
            "{'loss': 0.2078, 'grad_norm': 3.0945703983306885, 'learning_rate': 1.957025641025641e-05, 'epoch': 0.18}\n",
            "{'loss': 0.163, 'grad_norm': 1.482038974761963, 'learning_rate': 1.9560000000000002e-05, 'epoch': 0.19}\n",
            "{'loss': 0.2155, 'grad_norm': 5.654940605163574, 'learning_rate': 1.954974358974359e-05, 'epoch': 0.19}\n",
            "{'loss': 0.1841, 'grad_norm': 1.1404973268508911, 'learning_rate': 1.9539487179487182e-05, 'epoch': 0.19}\n",
            "{'loss': 0.2485, 'grad_norm': 0.8168524503707886, 'learning_rate': 1.952923076923077e-05, 'epoch': 0.19}\n",
            "{'loss': 0.2282, 'grad_norm': 0.5040217041969299, 'learning_rate': 1.951897435897436e-05, 'epoch': 0.19}\n",
            "{'loss': 0.2332, 'grad_norm': 7.270768642425537, 'learning_rate': 1.950871794871795e-05, 'epoch': 0.2}\n",
            "{'loss': 0.2544, 'grad_norm': 3.686814785003662, 'learning_rate': 1.9498461538461538e-05, 'epoch': 0.2}\n",
            "{'loss': 0.1435, 'grad_norm': 0.907067060470581, 'learning_rate': 1.948820512820513e-05, 'epoch': 0.2}\n",
            "{'loss': 0.2416, 'grad_norm': 10.423940658569336, 'learning_rate': 1.947794871794872e-05, 'epoch': 0.2}\n",
            "{'loss': 0.2194, 'grad_norm': 2.3914475440979004, 'learning_rate': 1.946769230769231e-05, 'epoch': 0.2}\n",
            "{'loss': 0.1229, 'grad_norm': 0.4618968963623047, 'learning_rate': 1.94574358974359e-05, 'epoch': 0.21}\n",
            "{'loss': 0.1505, 'grad_norm': 2.9364070892333984, 'learning_rate': 1.944717948717949e-05, 'epoch': 0.21}\n",
            "{'loss': 0.1976, 'grad_norm': 5.199424743652344, 'learning_rate': 1.9436923076923077e-05, 'epoch': 0.21}\n",
            "{'loss': 0.2362, 'grad_norm': 1.827354073524475, 'learning_rate': 1.9426666666666668e-05, 'epoch': 0.21}\n",
            "{'loss': 0.1541, 'grad_norm': 3.119229316711426, 'learning_rate': 1.941641025641026e-05, 'epoch': 0.21}\n",
            "{'loss': 0.1527, 'grad_norm': 4.413767337799072, 'learning_rate': 1.9406153846153848e-05, 'epoch': 0.22}\n",
            "{'loss': 0.28, 'grad_norm': 8.258386611938477, 'learning_rate': 1.9395897435897436e-05, 'epoch': 0.22}\n",
            "{'loss': 0.2206, 'grad_norm': 5.6409759521484375, 'learning_rate': 1.9385641025641027e-05, 'epoch': 0.22}\n",
            "{'loss': 0.2232, 'grad_norm': 3.26898455619812, 'learning_rate': 1.9375384615384615e-05, 'epoch': 0.22}\n",
            "{'loss': 0.1224, 'grad_norm': 3.5131659507751465, 'learning_rate': 1.9365128205128207e-05, 'epoch': 0.22}\n",
            "{'loss': 0.2485, 'grad_norm': 3.408006191253662, 'learning_rate': 1.93548717948718e-05, 'epoch': 0.23}\n",
            "{'loss': 0.177, 'grad_norm': 1.8020007610321045, 'learning_rate': 1.9344615384615387e-05, 'epoch': 0.23}\n",
            "{'loss': 0.1599, 'grad_norm': 4.068406105041504, 'learning_rate': 1.9334358974358975e-05, 'epoch': 0.23}\n",
            "{'loss': 0.2521, 'grad_norm': 4.5831379890441895, 'learning_rate': 1.9324102564102566e-05, 'epoch': 0.23}\n",
            "{'loss': 0.1572, 'grad_norm': 3.801044464111328, 'learning_rate': 1.9313846153846158e-05, 'epoch': 0.23}\n",
            "{'loss': 0.234, 'grad_norm': 4.307913303375244, 'learning_rate': 1.9303589743589746e-05, 'epoch': 0.24}\n",
            "{'loss': 0.1498, 'grad_norm': 0.5006620287895203, 'learning_rate': 1.9293333333333334e-05, 'epoch': 0.24}\n",
            "{'loss': 0.1952, 'grad_norm': 6.180337905883789, 'learning_rate': 1.9283076923076925e-05, 'epoch': 0.24}\n",
            "{'loss': 0.194, 'grad_norm': 5.926800727844238, 'learning_rate': 1.9272820512820513e-05, 'epoch': 0.24}\n",
            "{'loss': 0.2035, 'grad_norm': 4.210101127624512, 'learning_rate': 1.9262564102564105e-05, 'epoch': 0.24}\n",
            "{'loss': 0.2031, 'grad_norm': 4.066110134124756, 'learning_rate': 1.9252307692307693e-05, 'epoch': 0.25}\n",
            "{'loss': 0.2294, 'grad_norm': 6.330357551574707, 'learning_rate': 1.9242051282051285e-05, 'epoch': 0.25}\n",
            "{'loss': 0.2098, 'grad_norm': 0.8234314322471619, 'learning_rate': 1.9231794871794873e-05, 'epoch': 0.25}\n",
            "{'loss': 0.1805, 'grad_norm': 13.2898530960083, 'learning_rate': 1.9221538461538464e-05, 'epoch': 0.25}\n",
            "{'loss': 0.1376, 'grad_norm': 1.875888466835022, 'learning_rate': 1.9211282051282052e-05, 'epoch': 0.25}\n",
            "{'loss': 0.3165, 'grad_norm': 8.967025756835938, 'learning_rate': 1.9201025641025644e-05, 'epoch': 0.26}\n",
            "  6% 1287/20000 [03:46<55:30,  5.62it/s]"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "zBKHUbWynt_2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install --upgrade pip setuptools wheel\n",
        "\n",
        "# Uninstall problematic packages\n",
        "!pip uninstall -y numpy pandas scikit-learn tensorflow transformers\n",
        "\n",
        "# Install compatible versions\n",
        "!pip install numpy pandas scikit-learn tensorflow transformers"
      ],
      "metadata": {
        "id": "aMQTwiEhhMOn",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "e8289ccc-569d-454d-a08a-86c6644a90e3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pip in /usr/local/lib/python3.11/dist-packages (24.1.2)\n",
            "Collecting pip\n",
            "  Downloading pip-25.0.1-py3-none-any.whl.metadata (3.7 kB)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (75.2.0)\n",
            "Collecting setuptools\n",
            "  Downloading setuptools-79.0.0-py3-none-any.whl.metadata (6.5 kB)\n",
            "Requirement already satisfied: wheel in /usr/local/lib/python3.11/dist-packages (0.45.1)\n",
            "Downloading pip-25.0.1-py3-none-any.whl (1.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m25.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading setuptools-79.0.0-py3-none-any.whl (1.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m38.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: setuptools, pip\n",
            "  Attempting uninstall: setuptools\n",
            "    Found existing installation: setuptools 75.2.0\n",
            "    Uninstalling setuptools-75.2.0:\n",
            "      Successfully uninstalled setuptools-75.2.0\n",
            "  Attempting uninstall: pip\n",
            "    Found existing installation: pip 24.1.2\n",
            "    Uninstalling pip-24.1.2:\n",
            "      Successfully uninstalled pip-24.1.2\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "ipython 7.34.0 requires jedi>=0.16, which is not installed.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed pip-25.0.1 setuptools-79.0.0\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "_distutils_hack"
                ]
              },
              "id": "00da0a7af08246cbadf150dbe46d92fe"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found existing installation: numpy 2.0.2\n",
            "Uninstalling numpy-2.0.2:\n",
            "  Successfully uninstalled numpy-2.0.2\n",
            "Found existing installation: pandas 2.2.2\n",
            "Uninstalling pandas-2.2.2:\n",
            "  Successfully uninstalled pandas-2.2.2\n",
            "Found existing installation: scikit-learn 1.6.1\n",
            "Uninstalling scikit-learn-1.6.1:\n",
            "  Successfully uninstalled scikit-learn-1.6.1\n",
            "Found existing installation: tensorflow 2.18.0\n",
            "Uninstalling tensorflow-2.18.0:\n",
            "  Successfully uninstalled tensorflow-2.18.0\n",
            "Found existing installation: transformers 4.51.3\n",
            "Uninstalling transformers-4.51.3:\n",
            "  Successfully uninstalled transformers-4.51.3\n",
            "Collecting numpy\n",
            "  Downloading numpy-2.2.5-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (62 kB)\n",
            "Collecting pandas\n",
            "  Downloading pandas-2.2.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (89 kB)\n",
            "Collecting scikit-learn\n",
            "  Downloading scikit_learn-1.6.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (18 kB)\n",
            "Collecting tensorflow\n",
            "  Downloading tensorflow-2.19.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.1 kB)\n",
            "Collecting transformers\n",
            "  Downloading transformers-4.51.3-py3-none-any.whl.metadata (38 kB)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.14.1)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (3.6.0)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=24.3.25 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (25.2.10)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.6.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (18.1.1)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.4.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from tensorflow) (24.2)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (5.29.4)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (2.32.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from tensorflow) (79.0.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.17.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.0.1)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (4.13.2)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.17.2)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.71.0)\n",
            "Collecting tensorboard~=2.19.0 (from tensorflow)\n",
            "  Downloading tensorboard-2.19.0-py3-none-any.whl.metadata (1.8 kB)\n",
            "Requirement already satisfied: keras>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.8.0)\n",
            "Collecting numpy\n",
            "  Downloading numpy-2.1.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (62 kB)\n",
            "Requirement already satisfied: h5py>=3.11.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.13.0)\n",
            "Collecting ml-dtypes<1.0.0,>=0.5.1 (from tensorflow)\n",
            "  Downloading ml_dtypes-0.5.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (21 kB)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.37.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from transformers) (3.18.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.30.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.30.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2024.11.6)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.21.1)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.5.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.11/dist-packages (from transformers) (4.67.1)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from astunparse>=1.6.0->tensorflow) (0.45.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (2025.3.2)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.11/dist-packages (from keras>=3.5.0->tensorflow) (13.9.4)\n",
            "Requirement already satisfied: namex in /usr/local/lib/python3.11/dist-packages (from keras>=3.5.0->tensorflow) (0.0.8)\n",
            "Requirement already satisfied: optree in /usr/local/lib/python3.11/dist-packages (from keras>=3.5.0->tensorflow) (0.15.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (2025.1.31)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.11/dist-packages (from tensorboard~=2.19.0->tensorflow) (3.8)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from tensorboard~=2.19.0->tensorflow) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from tensorboard~=2.19.0->tensorflow) (3.1.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.11/dist-packages (from werkzeug>=1.0.1->tensorboard~=2.19.0->tensorflow) (3.0.2)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras>=3.5.0->tensorflow) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras>=3.5.0->tensorflow) (2.18.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich->keras>=3.5.0->tensorflow) (0.1.2)\n",
            "Downloading pandas-2.2.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (13.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.1/13.1 MB\u001b[0m \u001b[31m132.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading scikit_learn-1.6.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (13.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.5/13.5 MB\u001b[0m \u001b[31m143.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tensorflow-2.19.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (644.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m644.9/644.9 MB\u001b[0m \u001b[31m29.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading numpy-2.1.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (16.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m16.3/16.3 MB\u001b[0m \u001b[31m139.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading transformers-4.51.3-py3-none-any.whl (10.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.4/10.4 MB\u001b[0m \u001b[31m135.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading ml_dtypes-0.5.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.7/4.7 MB\u001b[0m \u001b[31m102.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tensorboard-2.19.0-py3-none-any.whl (5.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.5/5.5 MB\u001b[0m \u001b[31m111.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: numpy, tensorboard, pandas, ml-dtypes, scikit-learn, transformers, tensorflow\n",
            "  Attempting uninstall: tensorboard\n",
            "    Found existing installation: tensorboard 2.18.0\n",
            "    Uninstalling tensorboard-2.18.0:\n",
            "      Successfully uninstalled tensorboard-2.18.0\n",
            "  Attempting uninstall: ml-dtypes\n",
            "    Found existing installation: ml-dtypes 0.4.1\n",
            "    Uninstalling ml-dtypes-0.4.1:\n",
            "      Successfully uninstalled ml-dtypes-0.4.1\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "google-colab 1.0.0 requires pandas==2.2.2, but you have pandas 2.2.3 which is incompatible.\n",
            "tensorflow-decision-forests 1.11.0 requires tensorflow==2.18.0, but you have tensorflow 2.19.0 which is incompatible.\n",
            "tf-keras 2.18.0 requires tensorflow<2.19,>=2.18, but you have tensorflow 2.19.0 which is incompatible.\n",
            "numba 0.60.0 requires numpy<2.1,>=1.22, but you have numpy 2.1.3 which is incompatible.\n",
            "tensorflow-text 2.18.1 requires tensorflow<2.19,>=2.18.0, but you have tensorflow 2.19.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed ml-dtypes-0.5.1 numpy-2.1.3 pandas-2.2.3 scikit-learn-1.6.1 tensorboard-2.19.0 tensorflow-2.19.0 transformers-4.51.3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install datasets\n",
        "!pip install loguru"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WF6zjDyLlTod",
        "outputId": "84a81082-203d-4aa7-ba90-66e8373893ef"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: datasets in /usr/local/lib/python3.11/dist-packages (3.5.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from datasets) (3.18.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from datasets) (2.1.3)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (18.1.0)\n",
            "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.3.8)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from datasets) (2.2.3)\n",
            "Requirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.11/dist-packages (from datasets) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.66.3 in /usr/local/lib/python3.11/dist-packages (from datasets) (4.67.1)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.11/dist-packages (from datasets) (3.5.0)\n",
            "Requirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.70.16)\n",
            "Requirement already satisfied: fsspec<=2024.12.0,>=2023.1.0 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]<=2024.12.0,>=2023.1.0->datasets) (2024.12.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.11/dist-packages (from datasets) (3.11.15)\n",
            "Requirement already satisfied: huggingface-hub>=0.24.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.30.2)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from datasets) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from datasets) (6.0.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (6.4.3)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (0.3.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.19.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.24.0->datasets) (4.13.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (2025.1.31)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2025.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.17.0)\n",
            "Collecting loguru\n",
            "  Downloading loguru-0.7.3-py3-none-any.whl.metadata (22 kB)\n",
            "Downloading loguru-0.7.3-py3-none-any.whl (61 kB)\n",
            "Installing collected packages: loguru\n",
            "Successfully installed loguru-0.7.3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!cp -r /content/Detect_AI_Generated_Text/models/modelname_distilbert-base-uncased_version_v10-04-2025_size_100000_sources_outfox-fpe-daigt-persuade /content/drive/MyDrive/\n"
      ],
      "metadata": {
        "id": "PC9-bh3_n5E8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9caa7617-3653-4e70-edf0-501f40148452"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cp: cannot stat '/content/Detect_AI_Generated_Text/models/modelname_distilbert-base-uncased_version_v10-04-2025_size_100000_sources_outfox-fpe-daigt-persuade': No such file or directory\n"
          ]
        }
      ]
    }
  ]
}