{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Step 1: whenever runtime resets, need to re-clone the repo to Collab local."
      ],
      "metadata": {
        "id": "HW8s57WFZ6ct"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nH5BzzRMZnfW",
        "outputId": "d5da7ec9-9fd0-431e-fa64-5e308a5f0b1a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'Detect_AI_Generated_Text'...\n",
            "remote: Enumerating objects: 271, done.\u001b[K\n",
            "remote: Counting objects: 100% (139/139), done.\u001b[K\n",
            "remote: Compressing objects: 100% (106/106), done.\u001b[K\n",
            "remote: Total 271 (delta 80), reused 79 (delta 33), pack-reused 132 (from 1)\u001b[K\n",
            "Receiving objects: 100% (271/271), 91.48 MiB | 16.93 MiB/s, done.\n",
            "Resolving deltas: 100% (139/139), done.\n"
          ]
        }
      ],
      "source": [
        "# For initial cloning. Rerun when runtime resets.\n",
        "\n",
        "!git clone https://github.com/guyoron1/Detect_AI_Generated_Text.git\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Make sure we are working from GH root.\n",
        "%cd /content/Detect_AI_Generated_Text\n",
        "%mkdir ./data\n",
        "%mkdir ./models\n"
      ],
      "metadata": {
        "id": "PcPy-Q_XaHKE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "912145fd-4c65-4e1d-cd5d-3c4103a89fc3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/Detect_AI_Generated_Text\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step 2: mount Google Drive to save finetuned model there. You need to have external_sources.zip saved to Drive root beforehand (this is just a plaster solution because our Drives had run out of space towards the end of the assignment)"
      ],
      "metadata": {
        "id": "V4PUyFZjPx7W"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## Mount Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Copy the zip file to the local working directory\n",
        "!cp /content/drive/MyDrive/external_sources.zip .\n",
        "\n",
        "# Unzip it into the target directory (e.g., /content/Detect_AI_Generated_Text)\n",
        "!unzip -q external_sources.zip -d /content/Detect_AI_Generated_Text/"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "77CAItpaof1N",
        "outputId": "c5bae214-7dac-4a85-c756-76e080bfcba6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "replace /content/Detect_AI_Generated_Text/external_sources/llm-detect-ai-generated-text/train_prompts.csv? [y]es, [n]o, [A]ll, [N]one, [r]ename: שׁ\n",
            "error:  invalid response [שׁ]\n",
            "replace /content/Detect_AI_Generated_Text/external_sources/llm-detect-ai-generated-text/train_prompts.csv? [y]es, [n]o, [A]ll, [N]one, [r]ename: A\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Install requirements...\n",
        "!pip uninstall -y tokenizers\n",
        "!pip install transformers datasets tokenizers openai matplotlib scikit-learn matplotlib loguru"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BqkzTt7AvkpE",
        "outputId": "2f1015e0-f278-4b71-c12f-1303d5400506"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found existing installation: tokenizers 0.21.1\n",
            "Uninstalling tokenizers-0.21.1:\n",
            "  Successfully uninstalled tokenizers-0.21.1\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (4.51.3)\n",
            "Collecting datasets\n",
            "  Downloading datasets-3.5.1-py3-none-any.whl.metadata (19 kB)\n",
            "Collecting tokenizers\n",
            "  Downloading tokenizers-0.21.1-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.8 kB)\n",
            "Requirement already satisfied: openai in /usr/local/lib/python3.11/dist-packages (1.76.0)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (3.10.0)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (1.6.1)\n",
            "Collecting loguru\n",
            "  Downloading loguru-0.7.3-py3-none-any.whl.metadata (22 kB)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from transformers) (3.18.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.30.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.30.2)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2.0.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2024.11.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from transformers) (2.32.3)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.5.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.11/dist-packages (from transformers) (4.67.1)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (18.1.0)\n",
            "Collecting dill<0.3.9,>=0.3.0 (from datasets)\n",
            "  Downloading dill-0.3.8-py3-none-any.whl.metadata (10 kB)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from datasets) (2.2.2)\n",
            "Collecting xxhash (from datasets)\n",
            "  Downloading xxhash-3.5.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n",
            "Collecting multiprocess<0.70.17 (from datasets)\n",
            "  Downloading multiprocess-0.70.16-py311-none-any.whl.metadata (7.2 kB)\n",
            "Collecting fsspec<=2025.3.0,>=2023.1.0 (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets)\n",
            "  Downloading fsspec-2025.3.0-py3-none-any.whl.metadata (11 kB)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.11/dist-packages (from datasets) (3.11.15)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from openai) (4.9.0)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.11/dist-packages (from openai) (1.9.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from openai) (0.28.1)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from openai) (0.9.0)\n",
            "Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.11/dist-packages (from openai) (2.11.3)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.11/dist-packages (from openai) (1.3.1)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.11 in /usr/local/lib/python3.11/dist-packages (from openai) (4.13.2)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (1.3.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (4.57.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (1.4.8)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (11.2.1)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (3.2.3)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (2.9.0.post0)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.15.2)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (3.6.0)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.11/dist-packages (from anyio<5,>=3.5.0->openai) (3.10)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.6.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (6.4.3)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (0.3.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.20.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->openai) (2025.4.26)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->openai) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.16.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1.9.0->openai) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.1 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1.9.0->openai) (2.33.1)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1.9.0->openai) (0.4.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.7->matplotlib) (1.17.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.4.1)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2.4.0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2025.2)\n",
            "Downloading datasets-3.5.1-py3-none-any.whl (491 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m491.4/491.4 kB\u001b[0m \u001b[31m35.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tokenizers-0.21.1-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.0/3.0 MB\u001b[0m \u001b[31m102.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading loguru-0.7.3-py3-none-any.whl (61 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.6/61.6 kB\u001b[0m \u001b[31m7.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading dill-0.3.8-py3-none-any.whl (116 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.3/116.3 kB\u001b[0m \u001b[31m14.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading fsspec-2025.3.0-py3-none-any.whl (193 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m193.6/193.6 kB\u001b[0m \u001b[31m23.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading multiprocess-0.70.16-py311-none-any.whl (143 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m143.5/143.5 kB\u001b[0m \u001b[31m16.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading xxhash-3.5.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (194 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.8/194.8 kB\u001b[0m \u001b[31m22.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: xxhash, loguru, fsspec, dill, multiprocess, tokenizers, datasets\n",
            "  Attempting uninstall: fsspec\n",
            "    Found existing installation: fsspec 2025.3.2\n",
            "    Uninstalling fsspec-2025.3.2:\n",
            "      Successfully uninstalled fsspec-2025.3.2\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "torch 2.6.0+cu124 requires nvidia-cublas-cu12==12.4.5.8; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cublas-cu12 12.5.3.2 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-cuda-cupti-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cuda-cupti-cu12 12.5.82 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-cuda-nvrtc-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cuda-nvrtc-cu12 12.5.82 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-cuda-runtime-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cuda-runtime-cu12 12.5.82 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-cudnn-cu12==9.1.0.70; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cudnn-cu12 9.3.0.75 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-cufft-cu12==11.2.1.3; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cufft-cu12 11.2.3.61 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-curand-cu12==10.3.5.147; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-curand-cu12 10.3.6.82 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-cusolver-cu12==11.6.1.9; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cusolver-cu12 11.6.3.83 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-cusparse-cu12==12.3.1.170; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cusparse-cu12 12.5.1.3 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-nvjitlink-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-nvjitlink-cu12 12.5.82 which is incompatible.\n",
            "gcsfs 2025.3.2 requires fsspec==2025.3.2, but you have fsspec 2025.3.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed datasets-3.5.1 dill-0.3.8 fsspec-2025.3.0 loguru-0.7.3 multiprocess-0.70.16 tokenizers-0.21.1 xxhash-3.5.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step 3: run finetuning.py script from command line with required arguments.\n",
        "After concluding that these sources and that the dataset columns we had used are optimal, we mostly played around with the sources and with the sample size."
      ],
      "metadata": {
        "id": "f0hxxEApQGOw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# All we need is to run finetuning.py from the command line.\n",
        "!python finetuning.py \\\n",
        "  --sources outfox fpe daigt persuade \\\n",
        "  --save_dataset \\\n",
        "  --sample_size 100000\n"
      ],
      "metadata": {
        "id": "OGfvSzD-aaxN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1f0c6593-db06-4853-b074-609d1e643ad6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2025-05-01 21:09:51.454250: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1746133791.473878    3945 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1746133791.479970    3945 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2025-05-01 21:09:51.500441: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "config.json: 100% 662/662 [00:00<00:00, 4.98MB/s]\n",
            "Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n",
            "model.safetensors: 100% 3.13G/3.13G [00:13<00:00, 235MB/s]\n",
            "generation_config.json: 100% 147/147 [00:00<00:00, 756kB/s]\n",
            "tokenizer_config.json: 100% 2.54k/2.54k [00:00<00:00, 15.8MB/s]\n",
            "Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n",
            "spiece.model: 100% 792k/792k [00:00<00:00, 117MB/s]\n",
            "tokenizer.json: 100% 2.42M/2.42M [00:00<00:00, 3.70MB/s]\n",
            "special_tokens_map.json: 100% 2.20k/2.20k [00:00<00:00, 15.1MB/s]\n",
            "Device set to use cuda:0\n",
            "/content/Detect_AI_Generated_Text/fetch_data.py:110: DtypeWarning: Columns (17) have mixed types. Specify dtype option on import or set low_memory=False.\n",
            "  df = pd.read_csv(datapath)\n",
            "/content/Detect_AI_Generated_Text/format.py:82: DtypeWarning: Columns (17) have mixed types. Specify dtype option on import or set low_memory=False.\n",
            "  df = pd.read_csv(path)\n",
            "\n",
            "\u001b[32m2025-05-01 21:10:34.015\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m296\u001b[0m - \u001b[34m\u001b[1mGenerated column - Ones: 50000, Zeros: 50000\u001b[0m\n",
            "\u001b[32m2025-05-01 21:10:43.482\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m305\u001b[0m - \u001b[34m\u001b[1mLoaded and saved datasets successfuly. Performing finetuning.\u001b[0m\n",
            "\u001b[32m2025-05-01 21:10:43.483\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfinetune\u001b[0m:\u001b[36m126\u001b[0m - \u001b[34m\u001b[1mLoading tokenizer and model.\u001b[0m\n",
            "tokenizer_config.json: 100% 48.0/48.0 [00:00<00:00, 290kB/s]\n",
            "config.json: 100% 483/483 [00:00<00:00, 3.17MB/s]\n",
            "vocab.txt: 100% 232k/232k [00:00<00:00, 1.02MB/s]\n",
            "tokenizer.json: 100% 466k/466k [00:00<00:00, 17.8MB/s]\n",
            "Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n",
            "model.safetensors: 100% 268M/268M [00:00<00:00, 345MB/s]\n",
            "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "\u001b[32m2025-05-01 21:10:48.587\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfinetune\u001b[0m:\u001b[36m131\u001b[0m - \u001b[34m\u001b[1mModel moved to CUDA.\u001b[0m\n",
            "Map: 100% 80000/80000 [02:20<00:00, 568.50 examples/s]\n",
            "Map: 100% 20000/20000 [00:35<00:00, 555.84 examples/s]\n",
            "\u001b[32m2025-05-01 21:13:47.272\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfinetune\u001b[0m:\u001b[36m145\u001b[0m - \u001b[34m\u001b[1mDataset tokenized successfully.\u001b[0m\n",
            "/content/Detect_AI_Generated_Text/finetuning.py:164: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
            "  trainer = Trainer(\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m The `run_name` is currently set to the same value as `TrainingArguments.output_dir`. If this was not intended, please specify a different run name by setting the `TrainingArguments.run_name` parameter.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: (1) Create a W&B account\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: (2) Use an existing W&B account\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: (3) Don't visualize my results\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Enter your choice: 3\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: You chose \"Don't visualize my results\"\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.19.10\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: W&B syncing is set to \u001b[1m`offline`\u001b[0m in this directory. Run \u001b[1m`wandb online`\u001b[0m or set \u001b[1mWANDB_MODE=online\u001b[0m to enable cloud syncing.\n",
            "{'loss': 0.6855, 'grad_norm': 1.5981875658035278, 'learning_rate': 3.6e-07, 'epoch': 0.0}\n",
            "{'loss': 0.6907, 'grad_norm': 1.72158944606781, 'learning_rate': 7.6e-07, 'epoch': 0.0}\n",
            "{'loss': 0.6957, 'grad_norm': 1.2341835498809814, 'learning_rate': 1.1600000000000001e-06, 'epoch': 0.01}\n",
            "{'loss': 0.7019, 'grad_norm': 1.2365221977233887, 'learning_rate': 1.56e-06, 'epoch': 0.01}\n",
            "{'loss': 0.6939, 'grad_norm': 1.076704502105713, 'learning_rate': 1.9600000000000003e-06, 'epoch': 0.01}\n",
            "{'loss': 0.689, 'grad_norm': 1.856320858001709, 'learning_rate': 2.3600000000000003e-06, 'epoch': 0.01}\n",
            "{'loss': 0.6925, 'grad_norm': 1.281984806060791, 'learning_rate': 2.7600000000000003e-06, 'epoch': 0.01}\n",
            "{'loss': 0.6731, 'grad_norm': 1.2486780881881714, 'learning_rate': 3.1600000000000002e-06, 'epoch': 0.02}\n",
            "{'loss': 0.6648, 'grad_norm': 1.5070769786834717, 'learning_rate': 3.5600000000000002e-06, 'epoch': 0.02}\n",
            "{'loss': 0.6399, 'grad_norm': 1.3593075275421143, 'learning_rate': 3.96e-06, 'epoch': 0.02}\n",
            "{'loss': 0.5913, 'grad_norm': 2.47149920463562, 'learning_rate': 4.360000000000001e-06, 'epoch': 0.02}\n",
            "{'loss': 0.5466, 'grad_norm': 2.1410486698150635, 'learning_rate': 4.76e-06, 'epoch': 0.02}\n",
            "{'loss': 0.4921, 'grad_norm': 2.607314348220825, 'learning_rate': 5.1600000000000006e-06, 'epoch': 0.03}\n",
            "{'loss': 0.4289, 'grad_norm': 2.1306607723236084, 'learning_rate': 5.560000000000001e-06, 'epoch': 0.03}\n",
            "{'loss': 0.3494, 'grad_norm': 2.186319351196289, 'learning_rate': 5.9600000000000005e-06, 'epoch': 0.03}\n",
            "{'loss': 0.3155, 'grad_norm': 1.7061034440994263, 'learning_rate': 6.360000000000001e-06, 'epoch': 0.03}\n",
            "{'loss': 0.3093, 'grad_norm': 1.502162218093872, 'learning_rate': 6.760000000000001e-06, 'epoch': 0.03}\n",
            "{'loss': 0.2735, 'grad_norm': 2.4121527671813965, 'learning_rate': 7.16e-06, 'epoch': 0.04}\n",
            "{'loss': 0.2799, 'grad_norm': 2.4874207973480225, 'learning_rate': 7.5600000000000005e-06, 'epoch': 0.04}\n",
            "{'loss': 0.301, 'grad_norm': 5.50423526763916, 'learning_rate': 7.960000000000002e-06, 'epoch': 0.04}\n",
            "{'loss': 0.2892, 'grad_norm': 0.8830947279930115, 'learning_rate': 8.36e-06, 'epoch': 0.04}\n",
            "{'loss': 0.2839, 'grad_norm': 3.1235852241516113, 'learning_rate': 8.76e-06, 'epoch': 0.04}\n",
            "{'loss': 0.2011, 'grad_norm': 1.7219487428665161, 'learning_rate': 9.16e-06, 'epoch': 0.05}\n",
            "{'loss': 0.3549, 'grad_norm': 6.370559215545654, 'learning_rate': 9.56e-06, 'epoch': 0.05}\n",
            "{'loss': 0.3183, 'grad_norm': 2.4388351440429688, 'learning_rate': 9.960000000000001e-06, 'epoch': 0.05}\n",
            "{'loss': 0.3631, 'grad_norm': 6.1545233726501465, 'learning_rate': 1.036e-05, 'epoch': 0.05}\n",
            "{'loss': 0.3008, 'grad_norm': 2.2505173683166504, 'learning_rate': 1.0760000000000002e-05, 'epoch': 0.05}\n",
            "{'loss': 0.2664, 'grad_norm': 4.258127212524414, 'learning_rate': 1.1160000000000002e-05, 'epoch': 0.06}\n",
            "{'loss': 0.2763, 'grad_norm': 4.147476673126221, 'learning_rate': 1.156e-05, 'epoch': 0.06}\n",
            "{'loss': 0.236, 'grad_norm': 2.113551139831543, 'learning_rate': 1.196e-05, 'epoch': 0.06}\n",
            "{'loss': 0.23, 'grad_norm': 1.3885992765426636, 'learning_rate': 1.236e-05, 'epoch': 0.06}\n",
            "{'loss': 0.2207, 'grad_norm': 1.4792150259017944, 'learning_rate': 1.2760000000000001e-05, 'epoch': 0.06}\n",
            "{'loss': 0.1882, 'grad_norm': 2.3452746868133545, 'learning_rate': 1.3160000000000001e-05, 'epoch': 0.07}\n",
            "{'loss': 0.3384, 'grad_norm': 4.430643081665039, 'learning_rate': 1.3560000000000002e-05, 'epoch': 0.07}\n",
            "{'loss': 0.2762, 'grad_norm': 2.7971789836883545, 'learning_rate': 1.396e-05, 'epoch': 0.07}\n",
            "{'loss': 0.2986, 'grad_norm': 10.691878318786621, 'learning_rate': 1.4360000000000001e-05, 'epoch': 0.07}\n",
            "{'loss': 0.4336, 'grad_norm': 10.621253967285156, 'learning_rate': 1.4760000000000001e-05, 'epoch': 0.07}\n",
            "{'loss': 0.3179, 'grad_norm': 2.615339756011963, 'learning_rate': 1.516e-05, 'epoch': 0.08}\n",
            "{'loss': 0.2868, 'grad_norm': 3.430947780609131, 'learning_rate': 1.556e-05, 'epoch': 0.08}\n",
            "{'loss': 0.357, 'grad_norm': 2.6758310794830322, 'learning_rate': 1.5960000000000003e-05, 'epoch': 0.08}\n",
            "{'loss': 0.2141, 'grad_norm': 2.951314926147461, 'learning_rate': 1.636e-05, 'epoch': 0.08}\n",
            "{'loss': 0.2618, 'grad_norm': 3.310701370239258, 'learning_rate': 1.6760000000000002e-05, 'epoch': 0.08}\n",
            "{'loss': 0.178, 'grad_norm': 0.8814874887466431, 'learning_rate': 1.7160000000000002e-05, 'epoch': 0.09}\n",
            "{'loss': 0.3192, 'grad_norm': 5.23383903503418, 'learning_rate': 1.756e-05, 'epoch': 0.09}\n",
            "{'loss': 0.3657, 'grad_norm': 2.418262243270874, 'learning_rate': 1.796e-05, 'epoch': 0.09}\n",
            "{'loss': 0.2315, 'grad_norm': 2.2005412578582764, 'learning_rate': 1.8360000000000004e-05, 'epoch': 0.09}\n",
            "{'loss': 0.3684, 'grad_norm': 2.7844178676605225, 'learning_rate': 1.876e-05, 'epoch': 0.09}\n",
            "{'loss': 0.2093, 'grad_norm': 2.5569815635681152, 'learning_rate': 1.916e-05, 'epoch': 0.1}\n",
            "{'loss': 0.2442, 'grad_norm': 9.972506523132324, 'learning_rate': 1.9560000000000002e-05, 'epoch': 0.1}\n",
            "{'loss': 0.2339, 'grad_norm': 6.676756381988525, 'learning_rate': 1.9960000000000002e-05, 'epoch': 0.1}\n",
            "{'loss': 0.206, 'grad_norm': 2.2919318675994873, 'learning_rate': 1.999076923076923e-05, 'epoch': 0.1}\n",
            "{'loss': 0.1944, 'grad_norm': 2.789515733718872, 'learning_rate': 1.9980512820512822e-05, 'epoch': 0.1}\n",
            "{'loss': 0.2451, 'grad_norm': 8.063765525817871, 'learning_rate': 1.9970256410256414e-05, 'epoch': 0.11}\n",
            "{'loss': 0.2363, 'grad_norm': 1.8157614469528198, 'learning_rate': 1.9960000000000002e-05, 'epoch': 0.11}\n",
            "{'loss': 0.3113, 'grad_norm': 4.6371283531188965, 'learning_rate': 1.994974358974359e-05, 'epoch': 0.11}\n",
            "{'loss': 0.2122, 'grad_norm': 4.308547019958496, 'learning_rate': 1.993948717948718e-05, 'epoch': 0.11}\n",
            "{'loss': 0.2055, 'grad_norm': 1.2586690187454224, 'learning_rate': 1.9929230769230773e-05, 'epoch': 0.11}\n",
            "{'loss': 0.1718, 'grad_norm': 3.5915093421936035, 'learning_rate': 1.991897435897436e-05, 'epoch': 0.12}\n",
            "{'loss': 0.2133, 'grad_norm': 1.8046876192092896, 'learning_rate': 1.990871794871795e-05, 'epoch': 0.12}\n",
            "{'loss': 0.3728, 'grad_norm': 4.517943859100342, 'learning_rate': 1.989846153846154e-05, 'epoch': 0.12}\n",
            "{'loss': 0.2925, 'grad_norm': 2.182558059692383, 'learning_rate': 1.988820512820513e-05, 'epoch': 0.12}\n",
            "{'loss': 0.2585, 'grad_norm': 3.868872880935669, 'learning_rate': 1.9877948717948717e-05, 'epoch': 0.12}\n",
            "{'loss': 0.2615, 'grad_norm': 2.937610387802124, 'learning_rate': 1.986769230769231e-05, 'epoch': 0.13}\n",
            "{'loss': 0.2152, 'grad_norm': 1.1184827089309692, 'learning_rate': 1.98574358974359e-05, 'epoch': 0.13}\n",
            "{'loss': 0.2647, 'grad_norm': 5.878085613250732, 'learning_rate': 1.9847179487179488e-05, 'epoch': 0.13}\n",
            "{'loss': 0.2547, 'grad_norm': 7.8624186515808105, 'learning_rate': 1.983692307692308e-05, 'epoch': 0.13}\n",
            "{'loss': 0.2425, 'grad_norm': 5.979410648345947, 'learning_rate': 1.9826666666666668e-05, 'epoch': 0.13}\n",
            "{'loss': 0.2246, 'grad_norm': 1.3266018629074097, 'learning_rate': 1.981641025641026e-05, 'epoch': 0.14}\n",
            "{'loss': 0.1863, 'grad_norm': 7.029272556304932, 'learning_rate': 1.9806153846153847e-05, 'epoch': 0.14}\n",
            "{'loss': 0.3249, 'grad_norm': 4.316527843475342, 'learning_rate': 1.979589743589744e-05, 'epoch': 0.14}\n",
            "{'loss': 0.1584, 'grad_norm': 2.594491958618164, 'learning_rate': 1.9785641025641027e-05, 'epoch': 0.14}\n",
            "{'loss': 0.2962, 'grad_norm': 4.797909736633301, 'learning_rate': 1.9775384615384615e-05, 'epoch': 0.14}\n",
            "{'loss': 0.234, 'grad_norm': 3.001274347305298, 'learning_rate': 1.9765128205128206e-05, 'epoch': 0.15}\n",
            "{'loss': 0.1697, 'grad_norm': 1.8368960618972778, 'learning_rate': 1.9754871794871798e-05, 'epoch': 0.15}\n",
            "{'loss': 0.2166, 'grad_norm': 1.7623111009597778, 'learning_rate': 1.9744615384615386e-05, 'epoch': 0.15}\n",
            "{'loss': 0.1564, 'grad_norm': 1.622815489768982, 'learning_rate': 1.9734358974358974e-05, 'epoch': 0.15}\n",
            "{'loss': 0.2003, 'grad_norm': 2.2994277477264404, 'learning_rate': 1.9724102564102566e-05, 'epoch': 0.15}\n",
            "{'loss': 0.1984, 'grad_norm': 6.920971393585205, 'learning_rate': 1.9713846153846154e-05, 'epoch': 0.16}\n",
            "{'loss': 0.3405, 'grad_norm': 1.6881260871887207, 'learning_rate': 1.9703589743589745e-05, 'epoch': 0.16}\n",
            "{'loss': 0.1471, 'grad_norm': 1.5229301452636719, 'learning_rate': 1.9693333333333337e-05, 'epoch': 0.16}\n",
            "{'loss': 0.2465, 'grad_norm': 7.557176113128662, 'learning_rate': 1.9683076923076925e-05, 'epoch': 0.16}\n",
            "{'loss': 0.1363, 'grad_norm': 1.3308979272842407, 'learning_rate': 1.9672820512820513e-05, 'epoch': 0.16}\n",
            "{'loss': 0.1536, 'grad_norm': 4.492098331451416, 'learning_rate': 1.9662564102564104e-05, 'epoch': 0.17}\n",
            "{'loss': 0.2085, 'grad_norm': 2.726691484451294, 'learning_rate': 1.9652307692307696e-05, 'epoch': 0.17}\n",
            "{'loss': 0.2044, 'grad_norm': 1.3353883028030396, 'learning_rate': 1.9642051282051284e-05, 'epoch': 0.17}\n",
            "{'loss': 0.2336, 'grad_norm': 1.8282856941223145, 'learning_rate': 1.9631794871794872e-05, 'epoch': 0.17}\n",
            "{'loss': 0.1742, 'grad_norm': 2.2201316356658936, 'learning_rate': 1.9621538461538464e-05, 'epoch': 0.17}\n",
            "{'loss': 0.2237, 'grad_norm': 3.086104154586792, 'learning_rate': 1.9611282051282052e-05, 'epoch': 0.18}\n",
            "{'loss': 0.2604, 'grad_norm': 1.5557559728622437, 'learning_rate': 1.9601025641025643e-05, 'epoch': 0.18}\n",
            "{'loss': 0.2411, 'grad_norm': 2.8844683170318604, 'learning_rate': 1.9590769230769235e-05, 'epoch': 0.18}\n",
            "{'loss': 0.2031, 'grad_norm': 1.605351209640503, 'learning_rate': 1.9580512820512823e-05, 'epoch': 0.18}\n",
            "{'loss': 0.2078, 'grad_norm': 3.0945703983306885, 'learning_rate': 1.957025641025641e-05, 'epoch': 0.18}\n",
            "{'loss': 0.163, 'grad_norm': 1.482038974761963, 'learning_rate': 1.9560000000000002e-05, 'epoch': 0.19}\n",
            "{'loss': 0.2155, 'grad_norm': 5.654940605163574, 'learning_rate': 1.954974358974359e-05, 'epoch': 0.19}\n",
            "{'loss': 0.1841, 'grad_norm': 1.1404973268508911, 'learning_rate': 1.9539487179487182e-05, 'epoch': 0.19}\n",
            "{'loss': 0.2485, 'grad_norm': 0.8168524503707886, 'learning_rate': 1.952923076923077e-05, 'epoch': 0.19}\n",
            "{'loss': 0.2282, 'grad_norm': 0.5040217041969299, 'learning_rate': 1.951897435897436e-05, 'epoch': 0.19}\n",
            "{'loss': 0.2332, 'grad_norm': 7.270768642425537, 'learning_rate': 1.950871794871795e-05, 'epoch': 0.2}\n",
            "{'loss': 0.2544, 'grad_norm': 3.686814785003662, 'learning_rate': 1.9498461538461538e-05, 'epoch': 0.2}\n",
            "{'loss': 0.1435, 'grad_norm': 0.907067060470581, 'learning_rate': 1.948820512820513e-05, 'epoch': 0.2}\n",
            "{'loss': 0.2416, 'grad_norm': 10.423940658569336, 'learning_rate': 1.947794871794872e-05, 'epoch': 0.2}\n",
            "{'loss': 0.2194, 'grad_norm': 2.3914475440979004, 'learning_rate': 1.946769230769231e-05, 'epoch': 0.2}\n",
            "{'loss': 0.1229, 'grad_norm': 0.4618968963623047, 'learning_rate': 1.94574358974359e-05, 'epoch': 0.21}\n",
            "{'loss': 0.1505, 'grad_norm': 2.9364070892333984, 'learning_rate': 1.944717948717949e-05, 'epoch': 0.21}\n",
            "{'loss': 0.1976, 'grad_norm': 5.199424743652344, 'learning_rate': 1.9436923076923077e-05, 'epoch': 0.21}\n",
            "{'loss': 0.2362, 'grad_norm': 1.827354073524475, 'learning_rate': 1.9426666666666668e-05, 'epoch': 0.21}\n",
            "{'loss': 0.1541, 'grad_norm': 3.119229316711426, 'learning_rate': 1.941641025641026e-05, 'epoch': 0.21}\n",
            "{'loss': 0.1527, 'grad_norm': 4.413767337799072, 'learning_rate': 1.9406153846153848e-05, 'epoch': 0.22}\n",
            "{'loss': 0.28, 'grad_norm': 8.258386611938477, 'learning_rate': 1.9395897435897436e-05, 'epoch': 0.22}\n",
            "{'loss': 0.2206, 'grad_norm': 5.6409759521484375, 'learning_rate': 1.9385641025641027e-05, 'epoch': 0.22}\n",
            "{'loss': 0.2232, 'grad_norm': 3.26898455619812, 'learning_rate': 1.9375384615384615e-05, 'epoch': 0.22}\n",
            "{'loss': 0.1224, 'grad_norm': 3.5131659507751465, 'learning_rate': 1.9365128205128207e-05, 'epoch': 0.22}\n",
            "{'loss': 0.2485, 'grad_norm': 3.408006191253662, 'learning_rate': 1.93548717948718e-05, 'epoch': 0.23}\n",
            "{'loss': 0.177, 'grad_norm': 1.8020007610321045, 'learning_rate': 1.9344615384615387e-05, 'epoch': 0.23}\n",
            "{'loss': 0.1599, 'grad_norm': 4.068406105041504, 'learning_rate': 1.9334358974358975e-05, 'epoch': 0.23}\n",
            "{'loss': 0.2521, 'grad_norm': 4.5831379890441895, 'learning_rate': 1.9324102564102566e-05, 'epoch': 0.23}\n",
            "{'loss': 0.1572, 'grad_norm': 3.801044464111328, 'learning_rate': 1.9313846153846158e-05, 'epoch': 0.23}\n",
            "{'loss': 0.234, 'grad_norm': 4.307913303375244, 'learning_rate': 1.9303589743589746e-05, 'epoch': 0.24}\n",
            "{'loss': 0.1498, 'grad_norm': 0.5006620287895203, 'learning_rate': 1.9293333333333334e-05, 'epoch': 0.24}\n",
            "{'loss': 0.1952, 'grad_norm': 6.180337905883789, 'learning_rate': 1.9283076923076925e-05, 'epoch': 0.24}\n",
            "{'loss': 0.194, 'grad_norm': 5.926800727844238, 'learning_rate': 1.9272820512820513e-05, 'epoch': 0.24}\n",
            "{'loss': 0.2035, 'grad_norm': 4.210101127624512, 'learning_rate': 1.9262564102564105e-05, 'epoch': 0.24}\n",
            "{'loss': 0.2031, 'grad_norm': 4.066110134124756, 'learning_rate': 1.9252307692307693e-05, 'epoch': 0.25}\n",
            "{'loss': 0.2294, 'grad_norm': 6.330357551574707, 'learning_rate': 1.9242051282051285e-05, 'epoch': 0.25}\n",
            "{'loss': 0.2098, 'grad_norm': 0.8234314322471619, 'learning_rate': 1.9231794871794873e-05, 'epoch': 0.25}\n",
            "{'loss': 0.1805, 'grad_norm': 13.2898530960083, 'learning_rate': 1.9221538461538464e-05, 'epoch': 0.25}\n",
            "{'loss': 0.1376, 'grad_norm': 1.875888466835022, 'learning_rate': 1.9211282051282052e-05, 'epoch': 0.25}\n",
            "{'loss': 0.3165, 'grad_norm': 8.967025756835938, 'learning_rate': 1.9201025641025644e-05, 'epoch': 0.26}\n",
            "  6% 1287/20000 [03:46<55:30,  5.62it/s]"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# INSERT HERE \"cp\" STATEMENT CORRESPONDING TO THE MODEL YOU HAD JUST TRAINED, TO COPY IT TO YOUR LOCAL."
      ],
      "metadata": {
        "id": "PC9-bh3_n5E8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9caa7617-3653-4e70-edf0-501f40148452"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cp: cannot stat '/content/Detect_AI_Generated_Text/models/modelname_distilbert-base-uncased_version_v10-04-2025_size_100000_sources_outfox-fpe-daigt-persuade': No such file or directory\n"
          ]
        }
      ]
    }
  ]
}